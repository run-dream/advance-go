

## DNS

### **DNS** **介绍**

DNS（Domain Name System，域名系统），DNS 服务用于在网络请求时，将域名转为 IP 地址。能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的 IP 数串。

传统的基于 UDP 协议的公共 DNS 服务极易发生 DNS 劫持，从而造成安全问题。

**递归查询**

如果主机所询问的本地域名服务器不知道被查询域名的 *IP* 地址，那么本地域名服务器就以 *DNS* 客户的身份，向其他根域名服务器继续发出查询请求报文，而不是让该主机自己进行下一步的查询。

**迭代查询**

当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的 *IP* 地址，要么告诉本地域名服务器：你下一步应当向哪一个域名服务器进行查询。然后让本地域名服务器进行后续的查询，而不是替本地域名服务器进行后续的查询。

由此可见，客户端到 *Local DNS* 服务器，*Local DNS* 与上级 *DNS* 服务器之间属于递归查询；*DNS* 服务器与根 *DNS* 服务器之前属于迭代查询。

### DNS 问题

**Local DNS 劫持**

Local DNS 把域名劫持到其他域名，实现其不可告人的目的。

**域名缓存**

域名缓存就是 LocalDNS 缓存了业务的域名的解析结果，不向权威 DNS 发起递归。

- 保证用户访问流量在本网内消化：国内的各互联网接入运营商的带宽资源、网间结算费用、*IDC* 机房分布、网内 *ICP* 资源分布等存在较大差异。为了保证网内用户的访问质量，同时减少跨网结算，运营商在网内搭建了内容缓存服务器，通过把域名强行指向内容缓存服务器的 *IP* 地址，就实现了把本地本网流量完全留在了本地的目的。
- 推送广告：有部分 *LocalDNS* 会把部分域名解析结果的所指向的内容缓存，并替换成第三方广告联盟的广告。

**解析转发**

除了域名缓存以外，运营商的 LocalDNS 还存在解析转发的现象。

解析转发是指运营商自身不进行域名递归解析，而是把域名解析请求转发到其它运营商的递归 *DNS* 上的行为。

而部分小运营商为了节省资源，就直接将解析请求转发到了其它运营的递归 LocalDNS 上去了。

这样的直接后果就是权威 *DNS* 收到的域名解析请求的来源 *IP* 就成了其它运营商的 *IP*，最终导致用户流量被导向了错误的 *IDC*，用户访问变慢。

**LocalDNS 递归出口 NAT**

LocalDNS 递归出口 NAT 指的是运营商的 LocalDNS 按照标准的 DNS 协议进行递归，但是因为在网络上存在多出口且配置了目标路由 NAT，结果导致 LocalDNS 最终进行递归解析的时候的出口 IP 就有概率不为本网的 IP 地址。

这样的直接后果就是 *DNS* 收到的域名解析请求的来源 *IP* 还是成了其它运营商的 *IP*，最终导致用户流量被导向了错误的 *IDC*，用户访问变慢。

### **高可用** **DNS** **设计**

- 实时监控 + 商务推动：

  这种方案就是周期比较长，毕竟通过行政手段来推动运营商来解决这个问题是比较耗时的。

  另外我们通过大数据分析，得出的结论是 Top3 的问题用户均为移动互联网用户。对于这部分用户，我们有什么技术手段可以解决以上的问题呢？

  绕过自动分配 DNS，使用 114DNS 或 Google public DNS：

  - 如何在用户侧构造域名请求：对于 *PC* 端的客户端来说，构造一个标准的 *DNS* 请求包并不算什么难事。但在移动端要向一个指定的 *LocalDNS* 上发送标准的 *DNS* 请求包，而且要兼容各种 *iOS* 和 *Android* 的版本的话，技术上是可行的，只是兼容的成本会很高。
  - 推动用户修改配置极高：如果要推动用户手动修改 *PC* 的 *DNS* 配置的话，在 *PC* 端和手机客户端的 *WiFi* 下面还算勉强可行。但是要用户修改在移动互联网环境下的 *DNS* 配置，其难度不言而喻。

- 完全抛弃域名，自建 HTTPDNS 进行流量调度：

  如果要采用这种这种方案的话，首先你就得要拿到一份准确的 IP 地址库来判断用户的归属，然后再制定个协议搭个服务来做调度，然后再对接入层做调度改造。

  这种方案和2种方案一样，不是不能做，只是成本会比较高，尤其对于大体量业务规模如此庞大的公司而言。

  *当前主流的解决方案：**HTTPDNS** 出现了*

### 高可用 DNS 的最佳实践

HTTPDNS 利用 HTTP 协议与 DNS 服务器交互，代替了传统的基于 UDP 协议的 DNS 交互，绕开了运营商的 Local DNS，有效防止了域名劫持，提高域名解析效率。

另外，由于 DNS 服务器端获取的是真实客户端 IP 而非 Local DNS 的 IP，能够精确定位客户端地理位置、运营商信息，从而有效改进调度精确性。

由于 HTTP DNS 是通过 ip 直接请求 http获取服务器 A 记录地址，不存在向本地运营商询问 domain 解析过程，所以从根本避免了劫持问题。 

平均访问延迟下降：

- 由于是 *ip* 直接访问省掉了一次 *domain* 解析过程。

用户连接失败率下降：

- 通过算法降低以往失败率过高的服务器排序
- 通过时间近期访问过的数据提高服务器排序
- 通过历史访问成功记录提高服务器排序

根治域名解析异常：由于绕过了运营商的LocalDNS，用户解析域名的请求通过 HTTP 协议直接透传到了 HTTPDNS 服务器 IP 上，用户在客户端的域名解析请求将不会遭受到域名解析异常的困扰。

- 调度精准：*HTTPDNS* 能直接获取到用户 *IP*，通过结合 *IP* 地址库以及测速系统，可以保证将用户引导的访问最快的 *IDC* 节点上；
- 实现成本低廉：接入 *HTTPDNS* 的业务仅需要对客户端接入层做少量改造，无需用户手机进行 *root* 或越狱；而且由于 *HTTP* 协议请求构造非常简单，兼容各版本的移动操作系统更不成问题；另外 *HTTPDNS* 的后端配置完全复用现有权威 *DNS* 配置，管理成本也非常低。

如果只有一个 VIP，即可以增加 DNS 记录的 TTL，减少解析的延迟。

Anycast 可以使用一个 IP，将数据路由到最近的一组服务器，通过 BGP 宣告这个 IP，但是这存在两个问题：

- 如果某个节点承载过多的用户会过载
- *BGP* 路由计算可能会导致连接重置

因此一需要个 “稳定 Anycast” 技术来实现。



## CDN

### **CDN** **系统架构**

- 缓存代理

  通过智能 *DNS* 的筛选，用户的请求被透明地指向离他最近的省内骨干节点，最大限度的缩短用户信息的传输距离。

- 路由加速

  利用接入节点和中继节点或者多线节点互联互通。

- 安全保护

  无论面对是渗透还是 *DDoS*攻击，攻击的目标大都会被指向到了 *CDN*，进而保护了用户源站。

- 节省成本

  *CDN* 节点机房只需要在当地运营商的单线机房，或者带宽相对便宜的城市，采购成本低。

- 内容路由

  *DNS*系统、应用层重定向，传输层重定向。

- 内容分发

- - *PUSH*：主动分发，内容管理系统发起，将内容从源分发到 *CDN* 的 *Cache* 节点。
  - *PULL*：被动分发技术，用户请求驱动，用户请求内容中 *miss*，从源中或者其他 *CDN* 节点中实时获取内容。

- 内容存储

  随机读、顺序写、小文件的分布式存储。

- 内容管理

  提高内容服务的效率，提高 *CDN* 的缓存利用率。



### CDN 数据一致性

- PUSH

  不存在数据一致性问题。

- PULL

  缓存更新不及时，数据一致性问题，可设置缓存的失效时间，可以达到最终一致性。如果用户对一致性要求比较高也可以使用 *?version=xx* 的技术，也可以每次上传图片返回的*url*是不同的方式来代替版本号。

  *CDN* 存储的资源复本指定过期时间，因而缓存图像文件可在一个小时，一个月有效的。任何资源缓存在 *CDN* 上，是潜在历史版本，因为在源数据与副本之间总是有一个更新与传输的延迟。
  - Expires

    即在 *HTTP* 头中指明具体失效的时间*(HTTP/1.0)*

  - Cache Control

    *max-age* 在 *HTTP* 头中按秒指定失效的时间，优先级高于*Expires(HTTP/1.1)*

  - Last-Modified / If-Modified-Since 文件最后一次修改的时间（精度是秒，*HTTP/1.0*），需要 *Cache-Control* 过期。
  - Etag 当前资源在服务器的唯一标识（生成规则由服务器决定）优先级高于 *Last-Modified*

### 静态/动态 CDN 加速

- 静态 CDN 加速

  地理位置分散的用户最小化接收静态内容所需的跳数，直接从附近边缘的缓存中获取内容。 结果是显着降低了延迟和数据包丢失，加快了页面加载速度，并大大降低了原始基础架构的负载。

  - - 静态域名非主域名
    - 静态多域名和收敛
    - 静态资源版本化管理

- 动态CDN加速

  - TCP 优化

    设计算法来处理网络拥堵和包丢失，加快这些情况下的数据从 *CDN* 的恢复以及一些常见的 *TCP* 瓶颈。

  - Route optimization

    就是优化从源到用户端的请求的线路，以及可靠性，就是不断的测量计算得到更快更可靠的路线。

  - Connection management

    就是边缘和源之间，包括 *CDN* 之前的线路，采用长连接，而不是每一个请求一个连接

  - On-the-fly compression

    就是数据在刚刚离开源的时候就进行压缩，可以缩短在整个网络之中的流通时间。

  - SSL offload

    加速或者说减少一些安全监测，减少原服务器执行这种计算密集型的压力。

## 多活

### **多活系统**

- 业务分级

  按照一定的标准将业务进行分级，挑选出核心的业务，只为核心业务核心场景设计异地多活，降低方案整体复杂度和实现成本。例如：*1*、访问量；*2*、核心场景；*3*、收入；避免进入所有业务都要全部多活，分阶段分场景推进。

- 数据分类

  挑选出核心业务后，需要对核心业务相关的数据进一步分析，目的在于识别所有的数据及数据特征，这些数据特征会影响后面的方案设计。常见的数据特征分析维度有：*1*、数据量；*2*、唯一性；*3*、实时性；*4*、可丢失性；*5*、可恢复性；

- 数据同步

  确定数据的特点后，我们可以根据不同的数据设计不同的同步方案。常见的数据同步方案有：*1*、存储系统同步；*2*、消息队列同步；*3*、重复生成；

- 异常处理

  无论数据同步方案如何设计，一旦出现极端异常的情况，总是会有部分数据出现异常的。例如，同步延迟、数据丢失、数据不一致等。异常处理就是假设在出现这些问题时，系统将采取什么措施来应对。常见的异常处理措施：*1*、多通道同步；*2*、同步和异步访问；*3*、日志记录；*4*、补偿；



多活不是整个体系业务的多活，而是分成不同维度，不同重要性的多活，比如我们业务观看体验为主（淘宝以交易单元，买家为维度），那么第一大前提就是浏览、观看上的多活。我们将资源分为三类：

- *Global* 资源：多个 *Zone*（机房）共享访问的资源，每个 *Zone* 访问本 *Zone* 的资源，但是 *Global* 层面来说是单写 *Core Zone*（核心机房），即：单写*+*多读、利用数据复制（写*Zone* 单向）实现最终一致性方案实现；
- *Multi Zone* 资源：多个 *Zone* 分片部署，每个 *Zone* 拥有部分的 *Shard* 数据，比如我们按照用户维度拆分，用户 *A* 可能在 *ZoneA*，用户 *B* 可能在 *ZoneB*，即：多写*+*多读、利用数据复制（写 *Zone* 双向复制）方案实现；
- *Single Zone* 资源：单机房部署业务；



核心主要围绕：*PC/APP* 首页可观看、视频详情页可打开、账号可登陆、鉴权来开展，我们认为最合适我们观看类业务最合适的场景就是采用 *Global* 资源策略，对于社区类（评论、弹幕）可能会采用 *Multi Zone* 的策略。

### 蚂蚁金服多活

- GZone（Global Zone） 

  部署了不可拆分的数据和服务，这些数据和服务可能会被 RZone 依赖。GZone 在全局只有一组，数据只有一分。

- RZone （Region Zone）

  RZone 按照三地五机房来部署，RZone 服务无状态，数据库按照用户拆分成五个分片，每个分片有五个逻辑副本，其中只有一个副本是可以写的副本，其他副本基于 Paxos 协议实现一致性。每个 RZone 都是自包含的，拥有自己的数据，可以完成所有业务。

- CZone （City Zone）

  GZone 只在一个城市部署，RZone 跨城访问 GZone的数据和服务网络延迟较大；故在每个城市部署 CZone 作为 GZone 的只读副本，向本城市的 RZone 提供服务。

- RPO(Recovery Point Object)：表示机房级别故障时，未被同步的数据时长。考虑到 MySQL 在特殊情况下复制延迟较大情况下，RPO 设置为分钟级别，正常情况下 RPO 为秒级
- RTO(Recovery Target Object)：表示机房故障情况下，关键流程或系统切换恢复时间，一般为分钟级别
- WRT(Work Recovery Time)：表示故障时，由于 RPO 导致的未同步异常数据修复完成时长，一般为小时级别。

### 行业常见分布式架构分析

|      | 描述                                                         | 容量                                     | 容灾能力                                       | 高可用能力                                                   |
| ---- | ------------------------------------------------------------ | ---------------------------------------- | ---------------------------------------------- | ------------------------------------------------------------ |
| 单活 | 只有一个机房，所有服务器和数据库部署在此机房，所有服务均由此机房提供 | 千万级用户，亿级账户数，十万级日均业务量 | 机房内容灾（应用节点级）                       | 应用及数据机房内水平扩展（有上限），灰度发布（beta发布+分组发布） |
| 双活 | 有两个机房，应用服务无状态，在两个机房部署，数据库只在一个机房部署，两个机房双活，分别承担一部分流量 | 千万级用户，亿级账户数，百万级日均业务量 | 机房内容灾（应用节点级），机房间容灾（机房级） | 应用可跨机房水平扩展，数据库机房内水平扩展能力（有上限），双机房双活能力（应用），有跨机房数据库访问，灰度发布（基于机房） |
| 冷备 | 有两个机房，应用服务无状态，在两个机房部署，数据库主库在一个机房部署，备份库在另一个机房部署，主备之间数据弱一致 | 千万级用户，亿级账户数，百万级日均业务量 | 机房内容灾（应用节点级），机房间容灾（机房级） | 应用可跨机房水平扩展，数据库机房内水平扩展能力（有上限），双机房双活能力（应用），无跨机房数据库访问，备份数据弱一致 |



### 饿了么多活

业务过程中包含3个最重要的角色，分别是用户、商家和骑手，一个订单包含3个步骤：

1. 用户打开我们的*APP*，系统会推荐出用户位置附近的各种美食，推荐顺序中结合了用户习惯，推荐排序，商户的推广等。用户找到中意的食物 ，下单并支付，订单会流转到商家。
2. 商家接单并开始制作食物，制作完成后，系统调度骑手赶到店面，取走食物。
3. 骑手按照配送地址，把食物送到客户手中。

**业务内聚**：

单个订单的旅单过程，要在一个机房中完成，不允许跨机房调用。这个原则是为了保证实时性，旅单过程中不依赖另外一个机房的服务，才能保证没有延迟。我们称每个机房为一个 ezone，一个 ezone 包含了饿了么需要的各种服务。一笔业务能够内聚在一个 ezone 中，那么一个定单涉及的用户，商家，骑手，都会在相同的机房，这样订单在各个角色之间流转速度最快，不会因为各种异常情况导致延时。恰好我们的业务是地域化的，通过合理的地域划分，也能够实现业务内聚。

**可用性优先**：

当发生故障切换机房时，优先保证系统可用，首先让用户可以下单吃饭，容忍有限时间段内的数据不一致，在事后修复。每个 ezone 都会有全量的业务数据，当一个 ezone 失效后，其他的 ezone 可以接管用户。用户在一个ezone的下单数据，会实时的复制到其他ezone。

**保证数据正确**：

在确保可用的情况下，需要对数据做保护以避免错误，在切换和故障时，如果发现某些订单的状态在两个机房不一致，会锁定该笔订单，阻止对它进行更改，保证数据的正确。

**业务可感**：

因为基础设施还没有强大到可以抹去跨机房的差异，需要让业务感知多活逻辑，业务代码要做一些改造，包括：需要业务代码能够识别出业务数据的归属，只处理本 ezone 的数据，过滤掉无关的数据。完善业务状态机，能够在数据出现不一致的时候，通过状态机发现和纠正。



为了实现业务内聚，我们首先要选择一个**划分方法**（Sharding Key），对服务进行分区，让用户，商户，骑手能够正确的内聚到同一个 ezone 中。分区方案是整个多活的基础，它决定了之后的所有逻辑。

根据饿了么的业务特点，我们自然的选择地理位置（地理围栏，地理围栏主体按照省界划分，再加上局部微调）作为划分业务的单元，把地理位置上接近的用户，商户，骑手划分到同一个*ezone*，这样一个订单的履单流程就会在一个机房完成，能够保证最小的延时，在某个机房出现问题的时候，也可以按照地理位置把用户，商户，骑手打包迁移到别的机房即可。

基于地理位置划分规则，开发了统一的**流量路由层**（API Router），这一层负责对客户端过来的 API 调用进行路由，把流量导向到正确的 ezone。API Router 部署在多个公有云机房中，用户就近接入到公有云的API Router，还可以提升接入质量。

最基础的分流标签是地理位置，有了地理位置，*AR* 就能计算出正确的 *shard* 归属。但业务是很复杂的，并不是所有的调用都能直接关联到某个地理位置上，我们使用了一种分层的路由方案，核心的路由逻辑是地理位置，但是也支持其他的一些 *High Level Sharding Key*，这些 *Sharding Key* 由 *APIRouter* 转换为核心的 *Sharding Key*，具体如下图。这样既减少了业务的改造工作量，也可以扩展出更多的分区方法。除了入口处的路由，我们还开发了 *SOA Proxy*，用于路由*SOA*调用的，和*API Router*基于相同的路由规则。



#### 阿里多活

**基本原则**

- 按照买家纬度来进行数据切片
- 只取于买家链路相关的业务（单元）做多活
- 单元内最大限制的封闭
- 无法接受数据最终一致的跨单元单点写

**容灾**

- 同城容灾

*RZone1*出现故障先看同城容灾能力，我们目标将*RZone1*切换至同城容灾*RZone2*。先做数据库分片切换，*RZone1*对应的分片为分片*1*，把分片*1*在*RZone2*的副本提升为主副本，数据库副本提升完毕后将*RZone1*的流量切换至*RZone2*，实现同城容灾*RPO=0*、*RTO<1min*。

- 异地容灾

同样以*RZone1*故障为例。目标切换至*RZone3*，先做数据库切换，分片*1*在*RZone3*的副本切换成主副本，完成后将*RZone1*的流量切换至*RZone3*，实现异地容灾，该过程*RPO=0*、*RTO<1min*。

**路由**

流量路由模块核心是将用户的 *uid* 信息和对应的 *Zone* 信息植入到 *cookie* 中，供路由模块做精准路由。

服务路由分为本机房服务路由和跨机房服务路由调用。

- 本机房服务路由

服务调用端向本机房服务注册中心订阅服务，发现服务地址后做本机房服务路由调用。

- 跨机房服务路由调用

服务调用端向其他 *IDC* 的注册中心订阅服务地址，发现服务地址后做跨机房服务调用。

#### 存储

蚂蚁使用自研的分布式关系数据库 *OceanBase*，每个分片的数据库做*5*副本部署，部署地域实现三地五中心部署，*5*副本中有*3*副本实现强一致，如图所示可以实现同城、*IDC* 容灾和异地容灾。

#### 苏宁多活

*Cell*：业务可封闭收敛最小执行分片；业务对请求空间按一定维度（比如会员、门店等）划分分片。

*LDC*：逻辑数据中心，是由多个业务可封闭 *cell* 组成的集合单元，拥有独立的基础中间件系统（包括 *RPC*， *MQ*， *DNS* 等），以及出口网络等。

*PDC*：物理数据中心，指物理上独立的一栋建筑，一般每栋有好几层*,* 存放一系列机柜和上千和上万服务器*,* 构成一个 *PDC*。

*AZ*（*Available Zone*）：可用区，具有独立的故障隔离空间，拥有独立网络设施或电力设备，由相邻的单个或多个 *PDC* 组成。

*Region*：地理区域，有多可用区所组成的集合，区域之间故障域完全隔离。

分片服务：对应的数据仅在某个 *Cell* 存在，其它 *Cell* 不与交叉或共享，比如会员服务、订单服务等。

共享服务：所有 *Cell* 拥有相同的数据，相互共享，比如价格服务、商品服务等。

索引服务：用于索引数据提供服务，类似共享服务。

竞争 *(*控制*)* 服务：各个 *Cell* 相互操作同一个数据，为了保证数据一致性，需要在同一个数据中心进行控制，比如库存的扣减、用户注册等。

竞争 *Proxy* 服务：用于竞争服务前置服务，比如库存前置调拨服务。

为了确保数据高可用以及任何一个机房故障都可被接管，所有数据中心都包含全量数据，当主数据中心的变更将会实时同步到各个从数据中心。

数据中心之间延迟相对数据中心内部延迟较大，数据中心之间的同步一般采用异步复制方式。在机房故障等极端情况，将出现少量数据未同步到其它数据中心，针对此类故障场景，在机房恢复后，需要对未同步的数据进行人工修复。



#### **微信朋友圈异地多活**

因果关系对事件施加了一种顺序：因在果之前，消息发送在消息收取之前。而且就像现实生活中一样，一件事会顺序地导致另一件事发生：某个节点读取了一些数据然后写入一些结果，另一个节点读取其写入的内容，并依次写入一些其他内容等等。这些因果依赖的操作链定义了系统中的因果顺序，即什么在什么之前发生。从而我们也引出了分布式系统的因果一致性，如果一个系统服从因果关系所规定的顺序，我们说它是因果一致性的。

微信朋友圈某条状态的评论以及对评论的答复（也是评论）所构成的因果关系。

需要保证不同数据中心间的因果一致性来保证一个用户在刷朋友圈的时候不会出现看到评论所对应的答复，却看不到答复对应的评论。

由于网络在不同副本间复制数据时的延迟、中断等分布式系统中常见的场景，导致两条消息在同步到用户所在数据中心上的副本时已经乱序了。

按照这样的约定，当这两条数据同步到 *Kate*所在的数据中心副本时即使发生乱序，在刷朋友圈时，根据因果关系也可以将这个评论、答复的顺序调整到正确的、可阅读的方式。

- 每条评论都有一个唯一的且递增的数字 ID

那么背后肯定是一个*ID*生成器，各个数据中心都有一个这样的入口来获取本*IDC*内唯一、递增的*ID*。

- 每条新评论的 ID 都必须比本地已经见过的全局最大的 ID 大，确保因果关系

在香港的数据中心，当发表完*2*的评论，并且已经同步上海数据中心过来的*1 4 7*等 *ID* 的评论之后，如果再有香港地域下的用户发表新评论时，那么一定要大于当前香港数据中心能看到的全局最大 *ID*，此时是*7*，所以香港地域此时用户最新发表的评论的 *ID* 必须大于*7*。

- 广播本地看到的所有评论和新评论到其它IDC；相同 ID 的评论合并排重



本地域下的用户针对同一条朋友圈状态有评论时，该地域就负责申请一个全局 *ID*，然后将这个评论的事件广播给其他的数据中心。注意这个过程需要合并所有看到的序列，例如香港数据中心就合并*1 2 4 7 8*等针对同一条朋友圈状态的一系列评论事件 *IDs*，然后再整体广播出去，这样才能保证针对同一条状态的所有当前最新的事件整体被广播出去，否则此时香港*IDC* 只广播*8*的话，如果前面的事件序列在广播的中途丢失了，那么其他节点比如加拿大*IDC* 就会漏掉部分评论事件，这也是数据多重补位的措施。当然这个方法有一个前提就是：因为同一个朋友圈的发布状态，一般的评论不会很多，所以造成的数据冗余交互不会很大，否则是不行的。至于相同 *ID* 的评论合并排重，加拿大 *IDC* 会收到来自上海 *IDC* 的*1 4 7*事件系列，也会收到来自香港 *IDC* 同步过来的*1 4 7 8* 事件系列，这两个广播的事件系列有重复，所以需要去重。



### 账号多活

*A* 中心注册了用户，数据还未同步到 *B* 中心，此时 *A* 中心宕机，为了支持注册业务多活，那我们可以挑选 *B* 中心让用户去重新注册。

看起来很容易就支持多活了，但仔细思考一下会发现这样做会有问题：一个手机号只能注册一个账号，*A* 中心的数据没有同步过来，*B* 中心无法判断这个手机号是否重复，如果 *B* 中心让用户注册，后来 *A* 中心恢复了，发现数据有冲突，怎么解决？实际上是无法解决的，因为注册账号不能说挑选最后一个生效；而如果 *B* 中心不支持本来属于 *A* 中心的业务进行注册，注册业务的双活又成了空谈。

但很多朋友在考虑这个*“*业务*”*的时候，会不自觉的陷入一个思维误区：我要保证所有业务的*“*异地多活*”*！

**减少数据同步**

用户登录所产生的 *token* 或者 *session* 信息，数据量很大，但其实并不需要同步到其它业务中心，因为这些数据丢失后重新登录就可以了。

- 某些情况下可能出现消息队列同步也延迟了，用户在 *A* 中心注册，然后访问 *B* 中心的业务，此时 *B* 中心本地拿不到用户的账号数据。为了解决这个问题，*B* 中心在读取本地数据失败的时候，可以根据路由规则，再去 *A* 中心访问一次（这就是所谓的二次读取，第一次读取本地，本地失败后第二次读取对端）。
- 对于登录的 *session* 数据，由于数据量很大，我们可以不同步数据；但当用户在 *A* 中心登录后，然后又在 *B* 中心登录，*B* 中心拿到用户上传的 *session id* 后，根据路由判断 *session* 属于 *A* 中心，直接去 *A* 中心请求*session*数据即可，反之亦然，*A* 中心也可以到 *B* 中心去拿取*session* 数据。

**最终一致性**

*A* 机房注册了一个用户，业务上不要求能够在*50ms*内就同步到所有机房，正常情况下要求*5*分钟同步到所有机房即可，异常情况下甚至可以允许*1*小时或者*1*天后能够一致。

最终一致性在具体实现的时候，还需要根据不同的数据特征，进行差异化的处理，以满足业务需要。例如对*“*账号*”*信息来说，如果在 *A* 机房新注册的用户*5*分钟内正好跑到 *B* 机房了，此时 *B* 机房还没有这个用户的信息，为了保证业务的正确，*B* 机房就需要根据路由规则到 *A* 机房请求数据。

而对*“*用户信息*”*来说，*5*分钟后同步也没有问题，也不需要采取其它措施来弥补，但还是会影响用户体验，即用户看到了旧的用户信息，这个问题怎么解决呢？

